================================================================================
MOBILENETV2 for CIFAR-10 - Training, Pruning, Quantization & Compression
================================================================================

============================================================
STAGE 1: ORIGINAL MODEL
============================================================
Path: ./checkpoints/mobilenetv2_cifar10.pth
Evaluating accuracy...
Files already downloaded and verified
Files already downloaded and verified
  Model Format: Float32
  File Size: 8.77 MB
  Total Parameters: 2,270,846
  Weight Sparsity: 0.0%
  Test Accuracy: 94.87%

============================================================
STAGE 2: PRUNED MODEL
============================================================
Path: ./checkpoints/mobilenetv2_cifar10_pruned.pth
Evaluating accuracy...
Files already downloaded and verified
Files already downloaded and verified
  Model Format: Float32
  File Size: 8.77 MB
  Total Parameters: 2,270,846
  Weight Sparsity: 95.6%
  Test Accuracy: 94.40%
Comparison with Original:
   Size Compression: 1.0x
   Accuracy Change: -0.47%

============================================================
STAGE 3: QUANTIZED MODEL
============================================================
Path: ./checkpoints/mobilenetv2_pruned_symmetric_quantized_8bit.pth
Evaluating accuracy...
Files already downloaded and verified
Files already downloaded and verified
  Model Format: Float32
  File Size: 8.78 MB
  Total Parameters: 2,270,846
  Weight Sparsity: 95.6%
  Test Accuracy: 94.47%
Comparison with Pruned:
   Size Compression: 1.0x
   Accuracy Change: +0.07%

============================================================
STAGE 4: SPARSE COMPRESSED MODEL
============================================================
Path: ./checkpoints/mobilenetv2_sparse_compression.pth
Evaluating accuracy...
Files already downloaded and verified
Files already downloaded and verified
  Model Format: Sparse Compressed
  File Size: 0.99 MB
  Total Parameters: 2,270,846
  Weight Sparsity: 95.6%
  Test Accuracy: 94.47%
Comparison with Quantized:
   Size Compression: 8.8x
   Accuracy Change: +0.00%

================================================================================
COMPREHENSIVE COMPRESSION ANALYSIS
================================================================================
Stage                | Size (MB)  | Accuracy (%) | Compression 
----------------------------------------------------------------------
Original             |     8.77  |      94.87   | 1.0x (baseline)
Pruned               |     8.77  |      94.40   | 1.0x        
Quantized            |     8.78  |      94.47   | 1.0x        
Sparse Compressed    |     0.99  |      94.47   | 8.8x        

==================================================
FINAL COMPRESSION METRICS
==================================================
Total Model Compression: 8.8x
   Original size: 8.77 MB
   Final size: 0.99 MB
   Size reduction: 88.7%

Weight Compression: 14.7x
   Original weight size: 8.40 MB
   Final weight size: 0.57 MB
   Sparsity contribution: 22.7x
   Quantization contribution: 4.0x

Activation Compression: 4.0x
   Method: Dynamic 8-bit quantization during inference
   Baseline activation memory: 0.40 MB
   Compressed activation memory: 0.10 MB

Accuracy:
   Original accuracy: 94.87%
   Final accuracy: 94.47%
   Accuracy drop: 0.40%

================================================================================
